{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# laod data with pandas\n",
    "cols = ['user', 'item', 'rating', 'timestamp']\n",
    "train = pd.read_csv('ml-100k/ua.base', delimiter='\\t', names=cols)\n",
    "test = pd.read_csv('ml-100k/ua.test', delimiter='\\t', names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  timestamp\n",
       "0     1     1       5  874965758\n",
       "1     1     2       3  876893171\n",
       "2     1     3       4  878542960\n",
       "3     1     4       3  876893119\n",
       "4     1     5       3  889751712"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = max(train['user']); n_items = max(train['item']); n_ratings_train = len(train); n_ratings_test = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole = pd.concat([train, test])\n",
    "whole_sorted_by_user_time = whole.sort_values(['user', 'timestamp'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Last_movie = list()\n",
    "for i in range(n_users):\n",
    "    Last_movie.append(whole_sorted_by_user_time[whole_sorted_by_user_time['user'] == i+1].tail(1).iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_columns = n_users+2*n_items+1\n",
    "n_rows_train = n_ratings_train; n_rows_test = n_ratings_test\n",
    "X_train = np.zeros((n_rows_train, n_columns)); X_test = np.zeros((n_rows_test, n_columns))\n",
    "Y_train = np.zeros((n_rows_train, 1)); Y_test = np.zeros((n_rows_test, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(n_ratings_train):\n",
    "        index_user = train.iloc[i,0] - 1\n",
    "        index_item = train.iloc[i,1] - 1\n",
    "        index_last_item = Last_movie[index_user]\n",
    "        score = train.iloc[i,2]\n",
    "        time_stamp = train.iloc[i,3]\n",
    "        readable = datetime.datetime.fromtimestamp(time_stamp).isoformat()\n",
    "        month = readable[5:7]\n",
    "        X_train[i,index_user] = 1; X_train[i,n_users+index_item] = 1; X_train[i,n_users+n_items+index_last_item] = 1 \n",
    "        X_train[i,n_columns-1] = month; Y_train[i] = score\n",
    "for i in range(n_ratings_test):\n",
    "        index_user = test.iloc[i,0] - 1\n",
    "        index_item = test.iloc[i,1] - 1\n",
    "        index_last_item = Last_movie[index_user]\n",
    "        score = test.iloc[i,2]\n",
    "        time_stamp = test.iloc[i,3]\n",
    "        readable = datetime.datetime.fromtimestamp(time_stamp).isoformat()\n",
    "        month = readable[5:7]\n",
    "        X_test[i,index_user] = 1; X_test[i,n_users+index_item] = 1; X_test[i,n_users+n_items+index_last_item] = 1 \n",
    "        X_test[i,n_columns-1] = month; Y_test[i] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, n = X_train.shape\n",
    "\n",
    "# number of latent factors\n",
    "k = 40\n",
    "\n",
    "# design matrix\n",
    "X = tf.placeholder('float', shape=[None, n])\n",
    "# target vector\n",
    "y = tf.placeholder('float', shape=[None, 1])\n",
    "\n",
    "# bias and weights\n",
    "w0 = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.zeros([n]))\n",
    "\n",
    "# interaction factors, randomly initialized \n",
    "V = tf.Variable(tf.random_normal([k, n], stddev=0.01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate output with FM equation\n",
    "linear_terms = tf.add(w0, tf.reduce_sum(tf.multiply(W, X), 1, keep_dims=True))\n",
    "pair_interactions = (tf.multiply(0.5,\n",
    "                    tf.reduce_sum(\n",
    "                        tf.subtract(\n",
    "                            tf.pow( tf.matmul(X, tf.transpose(V)), 2),\n",
    "                            tf.matmul(tf.pow(X, 2), tf.transpose(tf.pow(V, 2)))),\n",
    "                        1, keep_dims=True)))\n",
    "y_hat = tf.add(linear_terms, pair_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 regularized sum of squares loss function over W and V\n",
    "lambda_w = tf.constant(0.001, name='lambda_w')\n",
    "lambda_v = tf.constant(0.001, name='lambda_v')\n",
    "\n",
    "l2_norm = (tf.reduce_sum(\n",
    "            tf.add(\n",
    "                tf.multiply(lambda_w, tf.pow(W, 2)),\n",
    "                tf.multiply(lambda_v, tf.pow(V, 2)))))\n",
    "\n",
    "error = tf.square(tf.subtract(y, y_hat))\n",
    "cost = tf.reduce_mean(error)\n",
    "loss = tf.add(cost, l2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_truth = tf.less(tf.abs(error), 0.5)\n",
    "acc = tf.reduce_mean(tf.cast(training_truth, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 :\n",
      "\n",
      "train Cost :  11.574\n",
      "Val Cost :  12.064\n",
      "Validation Accuracy :  0.0268293\n",
      "****************************************** \n",
      "\n",
      "epoch  1 :\n",
      "\n",
      "train Cost :  9.03173\n",
      "Val Cost :  9.85958\n",
      "Validation Accuracy :  0.0590668\n",
      "****************************************** \n",
      "\n",
      "epoch  2 :\n",
      "\n",
      "train Cost :  6.35791\n",
      "Val Cost :  7.4142\n",
      "Validation Accuracy :  0.0910923\n",
      "****************************************** \n",
      "\n",
      "epoch  3 :\n",
      "\n",
      "train Cost :  4.29541\n",
      "Val Cost :  5.1397\n",
      "Validation Accuracy :  0.167232\n",
      "****************************************** \n",
      "\n",
      "epoch  4 :\n",
      "\n",
      "train Cost :  3.40533\n",
      "Val Cost :  3.82698\n",
      "Validation Accuracy :  0.229374\n",
      "****************************************** \n",
      "\n",
      "epoch  5 :\n",
      "\n",
      "train Cost :  2.88252\n",
      "Val Cost :  3.15791\n",
      "Validation Accuracy :  0.255885\n",
      "****************************************** \n",
      "\n",
      "epoch  6 :\n",
      "\n",
      "train Cost :  2.42663\n",
      "Val Cost :  2.79208\n",
      "Validation Accuracy :  0.267444\n",
      "****************************************** \n",
      "\n",
      "epoch  7 :\n",
      "\n",
      "train Cost :  2.18451\n",
      "Val Cost :  2.66909\n",
      "Validation Accuracy :  0.262142\n",
      "****************************************** \n",
      "\n",
      "epoch  8 :\n",
      "\n",
      "train Cost :  2.12334\n",
      "Val Cost :  2.64834\n",
      "Validation Accuracy :  0.253234\n",
      "****************************************** \n",
      "\n",
      "epoch  9 :\n",
      "\n",
      "train Cost :  2.0437\n",
      "Val Cost :  2.51822\n",
      "Validation Accuracy :  0.258112\n",
      "****************************************** \n",
      "\n",
      "epoch  10 :\n",
      "\n",
      "train Cost :  1.82155\n",
      "Val Cost :  2.2016\n",
      "Validation Accuracy :  0.298409\n",
      "****************************************** \n",
      "\n",
      "epoch  11 :\n",
      "\n",
      "train Cost :  1.53215\n",
      "Val Cost :  1.82626\n",
      "Validation Accuracy :  0.355037\n",
      "****************************************** \n",
      "\n",
      "epoch  12 :\n",
      "\n",
      "train Cost :  1.33414\n",
      "Val Cost :  1.5585\n",
      "Validation Accuracy :  0.393531\n",
      "****************************************** \n",
      "\n",
      "epoch  13 :\n",
      "\n",
      "train Cost :  1.25599\n",
      "Val Cost :  1.41481\n",
      "Validation Accuracy :  0.401697\n",
      "****************************************** \n",
      "\n",
      "epoch  14 :\n",
      "\n",
      "train Cost :  1.20861\n",
      "Val Cost :  1.33248\n",
      "Validation Accuracy :  0.403818\n",
      "****************************************** \n",
      "\n",
      "epoch  15 :\n",
      "\n",
      "train Cost :  1.16274\n",
      "Val Cost :  1.29531\n",
      "Validation Accuracy :  0.397455\n",
      "****************************************** \n",
      "\n",
      "epoch  16 :\n",
      "\n",
      "train Cost :  1.13884\n",
      "Val Cost :  1.27795\n",
      "Validation Accuracy :  0.399046\n",
      "****************************************** \n",
      "\n",
      "epoch  17 :\n",
      "\n",
      "train Cost :  1.11814\n",
      "Val Cost :  1.2351\n",
      "Validation Accuracy :  0.415058\n",
      "****************************************** \n",
      "\n",
      "epoch  18 :\n",
      "\n",
      "train Cost :  1.08098\n",
      "Val Cost :  1.1759\n",
      "Validation Accuracy :  0.446872\n",
      "****************************************** \n",
      "\n",
      "epoch  19 :\n",
      "\n",
      "train Cost :  1.04089\n",
      "Val Cost :  1.13226\n",
      "Validation Accuracy :  0.476458\n",
      "****************************************** \n",
      "\n",
      "epoch  20 :\n",
      "\n",
      "train Cost :  1.01262\n",
      "Val Cost :  1.10596\n",
      "Validation Accuracy :  0.489926\n",
      "****************************************** \n",
      "\n",
      "epoch  21 :\n",
      "\n",
      "train Cost :  1.00247\n",
      "Val Cost :  1.1009\n",
      "Validation Accuracy :  0.490562\n",
      "****************************************** \n",
      "\n",
      "epoch  22 :\n",
      "\n",
      "train Cost :  1.00501\n",
      "Val Cost :  1.10869\n",
      "Validation Accuracy :  0.485048\n",
      "****************************************** \n",
      "\n",
      "epoch  23 :\n",
      "\n",
      "train Cost :  0.999599\n",
      "Val Cost :  1.09664\n",
      "Validation Accuracy :  0.499576\n",
      "****************************************** \n",
      "\n",
      "epoch  24 :\n",
      "\n",
      "train Cost :  0.982447\n",
      "Val Cost :  1.06946\n",
      "Validation Accuracy :  0.520149\n",
      "****************************************** \n",
      "\n",
      "epoch  25 :\n",
      "\n",
      "train Cost :  0.973107\n",
      "Val Cost :  1.05248\n",
      "Validation Accuracy :  0.532874\n",
      "****************************************** \n",
      "\n",
      "epoch  26 :\n",
      "\n",
      "train Cost :  0.973632\n",
      "Val Cost :  1.04248\n",
      "Validation Accuracy :  0.529905\n",
      "****************************************** \n",
      "\n",
      "epoch  27 :\n",
      "\n",
      "train Cost :  0.97217\n",
      "Val Cost :  1.03926\n",
      "Validation Accuracy :  0.525557\n",
      "****************************************** \n",
      "\n",
      "epoch  28 :\n",
      "\n",
      "train Cost :  0.968971\n",
      "Val Cost :  1.04415\n",
      "Validation Accuracy :  0.522269\n",
      "****************************************** \n",
      "\n",
      "epoch  29 :\n",
      "\n",
      "train Cost :  0.966177\n",
      "Val Cost :  1.04469\n",
      "Validation Accuracy :  0.525557\n",
      "****************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "# Launch the graph\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    sess.run(optimizer, feed_dict={X: X_train, y: Y_train})\n",
    "    cost_train = sess.run(cost, feed_dict={X: X_train, y: Y_train})\n",
    "    cost_val = sess.run(cost, feed_dict={X: X_test, y: Y_test})\n",
    "    acc_val = sess.run(acc, feed_dict={X: X_test, y: Y_test})\n",
    "    print(\"epoch \",epoch,\":\\n\")\n",
    "    print(\"train Cost : \", cost_train)\n",
    "    print(\"Val Cost : \", cost_val)\n",
    "    print(\"Validation Accuracy : \", acc_val)\n",
    "    print('****************************************** \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(np.array(cost_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98294288"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = sess.run(y_hat, feed_dict={X: X_train, y: Y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.69119453],\n",
       "       [ 3.42851424],\n",
       "       [ 3.39970422],\n",
       "       [ 3.54519677],\n",
       "       [ 3.2105372 ],\n",
       "       [ 3.43632531],\n",
       "       [ 3.65410852],\n",
       "       [ 3.72488856],\n",
       "       [ 3.63556552],\n",
       "       [ 3.61127949]], dtype=float32)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 3.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 4.],\n",
       "       [ 1.],\n",
       "       [ 5.],\n",
       "       [ 3.]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
